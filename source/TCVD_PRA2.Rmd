---
title: 'TCVD Práctica 2: ¿Cómo realizar la limpieza y análisis de datos?'
author: "Alfonso Manuel Carvajal, Eider Ibiricu"
date: "`r format(Sys.Date(),'%e de %B, %Y')`"
output:
  html_document:
    toc: no
    df_print: paged
  pdf_document:
    number_sections: yes
    toc: no
    df_print: kable
bibliography: references.bib
nocite: |
  @manualUOC, @awesome_tables, @RMarkdownCookbook, @ggplot2
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  warning = FALSE,
  message = FALSE,
  fig.align = 'center',
  fig.pos = "H",
  tidy.opts = list(width.cutoff = 60),
  tidy = FALSE
  )

kable_setup <- function(df){
  df %>% kable( "latex", booktabs = T) %>%
  kable_styling(latex_options = c(
    "striped",
    "HOLD_position",
    "scale_down"))
}
```


```{r libraries, message=FALSE, include=FALSE}
if(!require('ggplot2')) install.packages('ggplot2'); library('ggplot2')
if(!require('tidyr')) install.packages('tidyr'); library('tidyr')
if(!require('dplyr')) install.packages('dplyr'); library('dplyr')
if(!require('kableExtra')) install.packages('kableExtra'); library('kableExtra')
if(!require('gridExtra')) install.packages('gridExtra'); library('gridExtra')
if(!require('formatR')) install.packages('formatR'); library('formatR')
if(!require('devtools')) install.packages('devtools'); library('devtools')
if(!require('kaggler')) devtools::install_github("ldurazo/kaggler")
if(!require('ggcorrplot')) install.packages('ggcorrplot'); if(!require('car')) install.packages('car'); library('car')
if(!require('patchwork')) install.packages('patchwork'); library('patchwork')

```
# Descripción del dataset

El dataset *Heart Attack Analysis & Prediction* [kaggle](https://www.kaggle.com/datasets/rashikrahmanpritom/heart-attack-analysis-prediction-dataset) contiene datos para realizar una clasificación de pacientes que tengan riesgo de sufrir un ataque al corazón. 

Mediante este juego de datos es posible entrenar algoritmos que permitan un diagnóstico para futuros posibles pacientes. 


```{r download_data, message= FALSE, warning=FALSE}
#https://medium.com/mcd-unison/how-to-use-kaggle-api-to-download-datasets-in-r-312179c7a99c

library(readr)
library(kaggler)
kgl_auth(creds_file = 'kaggle.json')
response <- kgl_datasets_download_all(owner_dataset =
            "rashikrahmanpritom/heart-attack-analysis-prediction-dataset")

download.file(response[["url"]], "data/temp.zip", mode="wb")
unzip_result <- unzip("data/temp.zip", exdir = "data/", overwrite = TRUE)
unzip_result
heart_attack_data <- read_csv("data/heart.csv")
o2_saturation_data <- read.csv("data/o2Saturation.csv",header=F)

rm(response)
```
Las variables que encontramos en el dataset, según la descripción en *kaggle*:




- **Age**: Edad del individuo. (Variable numérica continua)

- **Sex**: Género del individuo (1 = masculino, 0 = femenino). (Variable categórica binaria)

- **cp**: Tipo de dolor en el pecho (categorica ordinal)

    - Value 1: typical angina
    
    - Value 2: atypical angina
    
    - Value 3: non-anginal pain
    
    - Value 4: asymptomatic

- **trtbps**: Presión arterial en reposo (en mm Hg) (Variable numérica continua)

- **chol**: Colesterol en mg/dl obtenido via sensor BMI (Variable numérica continua)


- **fbs**: Nivel de azúcar en sangre en ayunas (> 120 mg/dl, 1 = verdadero; 0 = falso). (Variable categórica binaria)

- **restecg**: Resultados electrocardiográficos en reposo. (Variable categórica ordinal)

    - Value 0: normal
    
    - Value 1: having ST-T wave abnormality (T wave inversions and/or ST elevation or depression of > 0.05 mV)
    
    - Value 2: showing probable or definite left ventricular hypertrophy by Estes' criteria

- **thalachh**: Máxima frecuencia cardíaca alcanzada. (Variable numérica continua)

- **exng**: Angina inducida por ejercicio (1 = sí; 0 = no). (Variable categórica binaria)

- **oldpeak**: Pico anterior, cambios en el segmento ST en un ECG (Variable numérica continua)

- **slp**: La pendiente del segmento ST en el pico de ejercicio (Variable numérica continua)

- **caa**: Número de vasos principales coloreados por fluoroscopia. (0-4) (categorical)

- **thall**: Talio en sangre.(Thallium Stress Test )(numerica)

- **output**: Diagnóstico de enfermedad cardíaca (estado del objetivo) (0 = menos probabilidad de ataque al corazón, 1 = más probabilidad de ataque al corazón). (Variable categórica binaria)


¿Por qué es importante y qué pregunta/problema
pretende responder?

# Integración y selección de los datos de interés a analizar. 

Puede ser el resultado de adicionar diferentes datasets o una subselección útil de los datos
originales, en base al objetivo que se quiera conseguir.

La recopilación y elección de información constituyen etapas fundamentales en cualquier tarea de análisis de datos. En relación a nuestro conjunto de información, estos procesos significarán identificar los factores que resultan más significativos para estimar un infarto al miocardio y optar por aquellos que nos brinden la mayor utilidad en nuestra investigación.

Dado que todas las variables en este conjunto de datos están directamente vinculadas a la salud cardiovascular y los riesgos asociados, todas podrían considerarse pertinentes. No obstante, puede que no todas estas variables contribuyan de la misma manera a la capacidad predictiva de un modelo de estimación de infartos al miocardio.

Por ejemplo, las variables `age`, `sex`, `cp`, `trtbps`, `chol`, `fbs`, `restecg`, `thalachh`, `exng`, `oldpeak`, `slp`, `caa`, y `thall` son todos posibles factores de riesgo para un infarto al miocardio y por lo tanto son de importancia para nuestro estudio. La variable `output` es la que nos gustaría pronosticar.

En consecuencia, el paso inicial en nuestro estudio será llevar a cabo un examen exploratorio de los datos para comprender de mejor manera la distribución y las relaciones de estas variables. Esto puede implicar visualizar la distribución de la información, calcular estadísticas descriptivas y analizar las correlaciones entre las diversas variables.

```{r}
head(heart_attack_data) %>% 
  kable_setup %>% 
  kable_paper(full_width = F)%>% 
  column_spec(c(3,7,14), width = "2 cm") %>%
  column_spec(c(1,5,9,12,13), width = "0.8 cm") %>%
  row_spec(0,bold=TRUE)
```
# Limpieza de los datos

Primero asignamos los tipos de datos a cada variable. En los **[comentarios](https://www.kaggle.com/datasets/rashikrahmanpritom/heart-attack-analysis-prediction-dataset/discussion/329925)** del dataset, hemos encontrado definiciones de los campos que nos ayudan a determinar el tipo de los datos:
```{r}
# Data types

data <- heart_attack_data %>% 
  mutate(
    sex = factor(sex, levels=c(1,0),labels = c("male","female")),
    cp = factor(cp,
                levels=c(0,1,2,3),
                labels=c("typical angina","atypical angina","non-anginal pain","asymptomatic")),
    fbs = factor(fbs,levels=c(0,1),labels = c(F,T)),
    restecg = factor(restecg,levels = c(0,1,2),
                     labels = c("normal","ST-T wave abnormality","left ventricular hypertrophy")),
    exng = factor(exng),
    slp = factor(slp,levels = c(0,1,2),
                 labels = c("unsloping","flat","downsloping")),
    caa = factor(caa),
    thall = factor(thall, 
                   levels = c(1,2,3),
                   labels = c("fixed defect","normal","reversable defect")),
    output = factor(output,levels=c(0,1),
                    labels = c("less chance of heart attack","more chance of heart attack"))
  )
```
Hacemos un resumen de los datos para identificar posibles valores nulos o atípicos. Esta tabla también nos permite entender los rangos en los que se mueven las variables.

También revisaremos si hay registros repetidos.
```{r}
# Summary
summary(data) 

# Duplicates
data %>% 
  unique() %>% 
  nrow()

data <- data %>% 
  unique()

```
## ¿Los datos contienen ceros o elementos vacíos? 

<!-- https://www.kaggle.com/datasets/rashikrahmanpritom/heart-attack-analysis-prediction-dataset/discussion/329925 -->
Representamos las distribuciones de las variables:


```{r, echo = FALSE}
## Numerical data
data_num <- data %>% 
  select_if(is.numeric)

# Histograms
data_num %>% 
pivot_longer(colnames(data_num)) %>% 
  as.data.frame() %>% 
  ggplot(aes(x = value)) +    # Draw each column as histogram
  geom_histogram() + 
  facet_wrap(~ name, scales = "free")+
  labs(title="Variables numéricas")

```
En el caso de las variables numéricas
```{r,echo = F}
## Categorical data
data_cat <- data %>% 
  select_if(~class(.) == 'factor')

# Barplots

p <- list()
cols = colnames(data_cat)
for(i in 1:length(cols)){
  col = cols[i]
  p[[i]] <- data_cat %>%
  ggplot(aes_string(col, fill = col)) + 
  geom_bar() + 
  ggtitle(paste0(col," distribution")) +
  # theme(axis.text.x = element_text(angle = 45, vjust = 0.5, hjust=1))
    theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank())
}
do.call(grid.arrange,c(p, ncol = 2,top="Variables categóricas"))

```
Vemos que la variable *thall* tiene valores nulos. Podemos considerar que estos registros como normales, por lo que les asignaremos el valor 2:
```{r}
data <- data %>% 
  mutate(
    thall = factor(if_else(is.na(as.numeric(thall)),2,as.numeric(thall)), 
                   levels = c(1,2,3),
                   labels = c("fixed defect","normal","reversable defect"))
  )

```


## Identifica y gestiona los valores extremos.
Estudiaremos los boxplots de las variables numéricas para observar si existen valores atípicos:

```{r, echo = FALSE}

# Boxplots
data_num %>% 
pivot_longer(colnames(data_num)) %>% 
  as.data.frame() %>% 
  ggplot(aes(y = value)) +    # Draw each column as histogram
  geom_boxplot(fill = "#404080", coef = 1.58) + 
  theme_minimal() +
  facet_wrap(~ name, scales = "free") +
  labs(title="Boxplots de variables numéricas")
```
Vemos que todas las variables menos *age* muestran valores que están alejados de las medias y la mayoría de observaciones. Esta gráfica identifica como atípico el valor que $x < Q_1 - IQR\cdot 1.58$ o $x < Q_3 - IQR\cdot 1.58$ donde $IQR = Q_3 - Q_1$. La manera en la que vamos a tratarlos es asignarles el valor más cercano para que no sean considerados *outliers*.

```{r}

for (col in colnames(data_num)){
  value = data[[col]][data[[col]] %in% boxplot.stats(data[[col]])$out]
  res <- quantile(data[[col]], probs = c(0,0.25,0.5,0.75,1))
  q1 <- res[[2]]
  q3 <- res[[4]]
  iqr <- q3 - q1
  min_thshld <- q1 - 1.58*iqr
  max_thshld <- q3 + 1.58*iqr
  data[[col]][data[[col]] < min_thshld] = min_thshld
  data[[col]][data[[col]] > max_thshld] = max_thshld
}


data %>% 
  select_if(is.numeric) %>% 
pivot_longer(colnames(data_num)) %>% 
  as.data.frame() %>% 
  ggplot(aes(y = value)) +    # Draw each column as histogram
  geom_boxplot(fill = "#404080", coef = 1.58) + 
  theme_minimal() +
  facet_wrap(~ name, scales = "free") +
  labs(title="Boxplots de variables numéricas \n Outliers corregidos")

```

# Análisis de los datos

## Selección de los grupos de datos que se quieren analizar/comparar.

Lo primero que haremos será estudiar la correlación entre las variables y también la que tienen con la variable *output*.

```{r, echo = FALSE}
corr <- round(cor(heart_attack_data), 1)
ggcorrplot(corr,  type = "lower",
   lab = TRUE, p.mat = cor_pmat(heart_attack_data)) +
  labs(title="Correlación entre variables")

```

Vemos que la variable *output* no tiene correlación significativa con *fbs* y *trtbps*, y con las que mayor correlación tiene son *caa*, *oldpeak*, *exng*, *thallachh* y *cp*.

Respecto al resto de variables, vemos parejas relacionadas como *oldpeak* y *slp*, *cp* y *exng*, *age* y *thallachh*, *thallachh* y *slp*.

Por otro lado, resulta curioso observar el la variable *chol* no se relaciona más que con *restecg*

## Comprobación de la normalidad y homogeneidad de la varianza.
Vamos a analizar las variables recién mencionadas, para determinar si son aptas para aplicar tests de comparación de grupos.

```{r}
data_compare <- data %>% 
  select(
    age,
    cp,
    fbs,
    thalachh,
    exng,
    oldpeak,
    slp,
    caa,
    output
  )
head(data_compare)

```

### Normalidad

Vamos a analizar si las variables numéricas tienen distribuciones normales. Para ello aplicamos el test *Shapiro-Wilk*:
```{r, echo = FALSE}

#númericas

#Shapiro-Wilk -- Levene
print(shapiro.test(data_compare$oldpeak))

print(shapiro.test(data_compare$thalachh))

print(shapiro.test(data_compare$age))

(
data_compare %>%
ggplot(aes(sample = oldpeak)) +
stat_qq() + stat_qq_line() +
labs(title="Normal Q-Q plot \n de oldpeak")
) + (
data_compare %>%
ggplot(aes(sample = thalachh)) +
stat_qq() + stat_qq_line() +
labs(title="Normal Q-Q plot \n de thalachh")
) + (
data_compare %>%
ggplot(aes(sample = age)) +
stat_qq() + stat_qq_line() +
labs(title="Normal Q-Q plot \n de age")
)
```

El test Shapiro-Wilk parte de la hipótesis de que la población está normalmente distribuida, por lo que si el resultado del p-valor es mayor que 0.05, podemos aceptar dicha hipótesis con un 95% de confianza.

En el caso anterior, vemos que no se puede aceptar que tanto *oldpeak* como *thalachh* estén normalmente distribuidas.

Podemos visualizar que las medias por los dos grupos objetivo no son iguales:

```{r, echo = FALSE}
(
data_compare %>%
  ggplot(aes(x=output, y=oldpeak, fill=output)) +
  geom_boxplot(alpha = 0.5) +
  scale_fill_manual(values=c("#404080","#69b3a2")) +
  theme(legend.position = "none",axis.text.x = element_text(angle = 30, hjust = 1))+
  ggtitle("Oldpeak by \n output group")
) + (
data_compare %>%
  ggplot(aes(x=output, y=thalachh, fill=output)) +
  geom_boxplot(alpha = 0.5) +
  scale_fill_manual(values=c("#404080","#69b3a2")) +
  theme(legend.position = "none",axis.text.x = element_text(angle = 30, hjust = 1))+
  ggtitle("thalachh by \n output group")
) + (
data_compare %>%
  ggplot(aes(x=output, y=age, fill=output)) +
  geom_boxplot(alpha = 0.5) +
  scale_fill_manual(values=c("#404080","#69b3a2")) +
  theme(legend.position = "none",axis.text.x = element_text(angle = 30, hjust = 1))+
  ggtitle("age by \n output group"))
```

### Homogeneidad de la varianza 

Aplicando el test de Levene, analizamos si las varianzas de los grupos de la variable objetivo son homogéneas para las tres variables numéricas que estamos analizando:
```{r}
print(leveneTest(oldpeak ~ output, data = data_compare,))
print(leveneTest(thalachh ~ output, data = data_compare,))
print(leveneTest(age ~ output, data = data_compare,))
```
En los tres casos, obtenemos que $p_{value} < 0.05$, por lo que rechazamos la hipótesis nula y concluímos que ninguna tiene varianzas homogeneas dentro de los grupos.

En resumen, ninguna de las variables analizadas cumplen con el supuesto de normalidad y homogeneidad de varianza.




## Aplicación de pruebas estadísticas para comparar los grupos de datos.

### Prueba de chi-cuadrado

AHora vamos a analizar la correlación entre las variables categóricas y la variable objetivo mediante el test *Chi-cuadrado*, el cual indica si existe correlación significativa entre dos variables cualitativas.

```{r}
#categoricas Chi-quadrado
# Variable "caa"
table_caa <- table(data_compare$caa, data_compare$output)
print(chisq.test(table_caa))

# Variable "exng"
table_exng <- table(data_compare$exng, data_compare$output)
print(chisq.test(table_exng))

# Variable "cp"
table_cp <- table(data_compare$cp, data_compare$output)
print(chisq.test(table_cp))


```

1. Variable `cp`: El valor p es menor que 2.2e-16, que es menor que 0.05. Por lo tanto, rechazamos la hipótesis nula y concluimos que hay una asociación significativa entre las categorías de `cp`.

2. Variable `caa`: El valor p es 3.771e-15, que es menor que 0.05. Por lo tanto, rechazamos la hipótesis nula y concluimos que hay una asociación significativa entre las categorías de `caa`.

3. Variable `exng`: El valor p es 9.556e-14, que es menor que 0.05. Por lo tanto, rechazamos la hipótesis nula y concluimos que hay una asociación significativa entre las categorías de `exng`.

En resumen, todas las variables categóricas parecen tener una relación significativa con la variable de resultado.


### Modelo de regresión logística

Al tratarse de una variable objetivo de dos clases, vamos ajustar un modelo de regresión logística. 

```{r}
# wilcox oldpeak
res <- wilcox.test(oldpeak ~ output, data = data_compare)
print(res)
# kruskal thalachh
res <- kruskal.test(thalachh ~ output, data = data_compare)
print(res)

# Regresión logística utilizando 'cp', 'caa' y 'exng' como predictores
model <- glm(output ~ cp + caa + exng, data = data_compare, family = binomial)
summary(model)


```

# Conclusiones

Revisión de correlaciones: En nuestro análisis, descubrimos que 'output' no parece estar fuertemente ligado con 'fbs' o 'trtbps'. Sin embargo, observamos una fuerte relación entre 'output' y otras variables como 'caa', 'oldpeak', 'exng', 'thallachh' y 'cp'. Esto podría indicar que estas últimas variables tienen más relevancia para prever el riesgo de ataque cardíaco.

Distribución y varianza de las variables: Según las pruebas de Shapiro-Wilk, 'oldpeak' y 'thalachh' no se distribuyen normalmente. Además, el test de Levene indica que la varianza entre 'oldpeak', 'thalachh' y 'age' no es uniforme. Este es un aspecto clave, ya que varios métodos estadísticos requieren una distribución normal y una varianza homogénea.

Análisis de Chi-cuadrado: Según las pruebas de chi-cuadrado, existe una relación significativa entre 'output' y las variables categóricas 'cp', 'caa' y 'exng'.

Regresión logística: Nuestro modelo sugiere que 'cp', 'caa' y 'exng' podrían ser buenos indicadores de 'output'. Por ejemplo, se encontró que diferentes tipos de angina ('cp') y la cantidad de vasos visibles en la fluoroscopia ('caa') tienen una relación significativa con el riesgo de ataque cardíaco. Además, la angina inducida por ejercicio ('exng') parece estar inversamente relacionada con 'output', lo que sugiere que su presencia podría disminuir la probabilidad de un ataque cardíaco.

En resumen, 'cp', 'caa', 'exng', 'oldpeak' y 'thalachh' podrían ser importantes para predecir la probabilidad de un ataque cardíaco. Sin embargo, dado que ninguna de las variables cumple con las premisas de normalidad y varianza homogénea, estos hallazgos deben tomarse con cierto escepticismo. Sería prudente considerar técnicas estadísticas que no requieran estos supuestos para un análisis más confiable.


