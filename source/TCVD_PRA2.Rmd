---
title: 'TCVD Práctica 2: ¿Cómo realizar la limpieza y análisis de datos?'
author: 
   Alfonso Manuel Carvajal, Eider Ibiricu
date: '`r format(Sys.Date(),"%e de %B, %Y")`'
output: 
  pdf_document:
    number_sections: yes
    toc: no
    df_print: "kable"
bibliography: references.bib
nocite: |
  @manualUOC, @awesome_tables, @RMarkdownCookbook, @ggplot2
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  warning = FALSE,
  message = FALSE,
  fig.align = 'center',
  fig.pos = "H",
  tidy.opts = list(width.cutoff = 60),
  tidy = FALSE
  )

kable_setup <- function(df){
  df %>% kable( "latex", booktabs = T) %>%
  kable_styling(latex_options = c(
    "striped",
    "HOLD_position",
    "scale_down"))
}
```


```{r libraries, message=FALSE, include=FALSE}
if(!require('ggplot2')) install.packages('ggplot2'); library('ggplot2')
if(!require('tidyr')) install.packages('tidyr'); library('tidyr')
if(!require('dplyr')) install.packages('dplyr'); library('dplyr')
if(!require('kableExtra')) install.packages('kableExtra'); library('kableExtra')
if(!require('gridExtra')) install.packages('gridExtra'); library('gridExtra')
if(!require('formatR')) install.packages('formatR'); library('formatR')
if(!require('devtools')) install.packages('devtools'); library('devtools')
if(!require('kaggler')) devtools::install_github("ldurazo/kaggler")
```
# Descripción del dataset

El dataset *Heart Attack Analysis & Prediction* [kaggle](https://www.kaggle.com/datasets/rashikrahmanpritom/heart-attack-analysis-prediction-dataset) contiene datos para realizar una clasificación de pacientes que tengan riesgo de sufrir un ataque al corazón. 

Mediante este juego de datos es posible entrenar algoritmos que permitan un diagnóstico para futuros posibles pacientes. 


```{r download_data, message= FALSE, warning=FALSE}
#https://medium.com/mcd-unison/how-to-use-kaggle-api-to-download-datasets-in-r-312179c7a99c

library(readr)
library(kaggler)
kgl_auth(creds_file = 'kaggle.json')
response <- kgl_datasets_download_all(owner_dataset =
            "rashikrahmanpritom/heart-attack-analysis-prediction-dataset")

download.file(response[["url"]], "data/temp.zip", mode="wb")
unzip_result <- unzip("data/temp.zip", exdir = "data/", overwrite = TRUE)
unzip_result
heart_attack_data <- read_csv("data/heart.csv")
o2_saturation_data <- read.csv("data/o2Saturation.csv",header=F)

rm(response)
```
Las variables que encontramos en el dataset, según la descripción en *kaggle*:




- **Age**: Edad del individuo. (Variable numérica continua)

- **Sex**: Género del individuo (1 = masculino, 0 = femenino). (Variable categórica binaria)

- **cp**: Tipo de dolor en el pecho (categorica ordinal)

    - Value 1: typical angina
    
    - Value 2: atypical angina
    
    - Value 3: non-anginal pain
    
    - Value 4: asymptomatic

- **trtbps**: Presión arterial en reposo (en mm Hg) (Variable numérica continua)

- **chol**: Colesterol en mg/dl obtenido via sensor BMI (Variable numérica continua)


- **fbs**: Nivel de azúcar en sangre en ayunas (> 120 mg/dl, 1 = verdadero; 0 = falso). (Variable categórica binaria)

- **restecg**: Resultados electrocardiográficos en reposo. (Variable categórica ordinal)

    - Value 0: normal
    
    - Value 1: having ST-T wave abnormality (T wave inversions and/or ST elevation or depression of > 0.05 mV)
    
    - Value 2: showing probable or definite left ventricular hypertrophy by Estes' criteria

- **thalachh**: Máxima frecuencia cardíaca alcanzada. (Variable numérica continua)

- **exng**: Angina inducida por ejercicio (1 = sí; 0 = no). (Variable categórica binaria)

- **oldpeak**: Pico anterior, cambios en el segmento ST en un ECG (Variable numérica continua)

- **slp**: La pendiente del segmento ST en el pico de ejercicio (Variable numérica continua)

- **caa**: Número de vasos principales coloreados por fluoroscopia. (0-4) (categorical)

- **thall**: Talio en sangre.(Thallium Stress Test )(numerica)

- **output**: Diagnóstico de enfermedad cardíaca (estado del objetivo) (0 = menos probabilidad de ataque al corazón, 1 = más probabilidad de ataque al corazón). (Variable categórica binaria)


¿Por qué es importante y qué pregunta/problema
pretende responder?

# Integración y selección de los datos de interés a analizar. 

Puede ser el resultado de adicionar diferentes datasets o una subselección útil de los datos
originales, en base al objetivo que se quiera conseguir.

La recopilación y elección de información constituyen etapas fundamentales en cualquier tarea de análisis de datos. En relación a nuestro conjunto de información, estos procesos significarán identificar los factores que resultan más significativos para estimar un infarto al miocardio y optar por aquellos que nos brinden la mayor utilidad en nuestra investigación.

Dado que todas las variables en este conjunto de datos están directamente vinculadas a la salud cardiovascular y los riesgos asociados, todas podrían considerarse pertinentes. No obstante, puede que no todas estas variables contribuyan de la misma manera a la capacidad predictiva de un modelo de estimación de infartos al miocardio.

Por ejemplo, las variables `age`, `sex`, `cp`, `trtbps`, `chol`, `fbs`, `restecg`, `thalachh`, `exng`, `oldpeak`, `slp`, `caa`, y `thall` son todos posibles factores de riesgo para un infarto al miocardio y por lo tanto son de importancia para nuestro estudio. La variable `output` es la que nos gustaría pronosticar.

En consecuencia, el paso inicial en nuestro estudio será llevar a cabo un examen exploratorio de los datos para comprender de mejor manera la distribución y las relaciones de estas variables. Esto puede implicar visualizar la distribución de la información, calcular estadísticas descriptivas y analizar las correlaciones entre las diversas variables.

```{r}
head(data) %>% 
  kable_setup %>% 
  kable_paper(full_width = F)%>% 
  column_spec(c(3,7,14), width = "2 cm") %>%
  column_spec(c(1,5,9,12,13), width = "0.8 cm") %>% 
  row_spec(0,bold=TRUE)
```
# Limpieza de los datos

Primero asignamos los tipos de datos a cada variable. En los **[comentarios](https://www.kaggle.com/datasets/rashikrahmanpritom/heart-attack-analysis-prediction-dataset/discussion/329925)** del dataset, hemos encontrado definiciones de los campos que nos ayudan a determinar el tipo de los datos:
```{r}
# Data types

data <- heart_attack_data %>% 
  mutate(
    sex = factor(sex, levels=c(1,0),labels = c("male","female")),
    cp = factor(cp,
                levels=c(0,1,2,3),
                labels=c("typical angina","atypical angina","non-anginal pain","asymptomatic")),
    fbs = factor(fbs,levels=c(0,1),labels = c(F,T)),
    restecg = factor(restecg,levels = c(0,1,2),
                     labels = c("normal","ST-T wave abnormality","left ventricular hypertrophy")),
    exng = factor(exng),
    slp = factor(slp,levels = c(0,1,2),
                 labels = c("unsloping","flat","downsloping")),
    caa = factor(caa),
    thall = factor(thall, 
                   levels = c(1,2,3),
                   labels = c("fixed defect","normal","reversable defect")),
    output = factor(output,levels=c(0,1),
                    labels = c("less chance of heart attack","more chance of heart attack"))
  )
```
Hacemos un resumen de los datos para identificar posibles valores nulos o atípicos. Esta tabla también nos permite entender los rangos en los que se mueven las variables.

También revisaremos si hay registros repetidos.
```{r}
# Summary
summary(data) 

# Duplicates
data %>% 
  unique() %>% 
  nrow()

data <- data %>% 
  unique()

```
## ¿Los datos contienen ceros o elementos vacíos? 

<!-- https://www.kaggle.com/datasets/rashikrahmanpritom/heart-attack-analysis-prediction-dataset/discussion/329925 -->
Representamos las distribuciones de las variables:


```{r, echo = FALSE}
## Numerical data
data_num <- data %>% 
  select_if(is.numeric)

# Histograms
data_num %>% 
pivot_longer(colnames(data_num)) %>% 
  as.data.frame() %>% 
  ggplot(aes(x = value)) +    # Draw each column as histogram
  geom_histogram() + 
  facet_wrap(~ name, scales = "free")+
  labs(title="Variables numéricas")

```
En el caso de las variables numéricas
```{r,echo = F}
## Categorical data
data_cat <- data %>% 
  select_if(~class(.) == 'factor')

# Barplots

p <- list()
cols = colnames(data_cat)
for(i in 1:length(cols)){
  col = cols[i]
  p[[i]] <- data_cat %>%
  ggplot(aes_string(col, fill = col)) + 
  geom_bar() + 
  ggtitle(paste0(col," distribution")) +
  # theme(axis.text.x = element_text(angle = 45, vjust = 0.5, hjust=1))
    theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank())
}
do.call(grid.arrange,c(p, ncol = 2,top="Variables categóricas"))

```
Vemos que la variable *thall* tiene valores nulos. Podemos considerar que estos registros como normales, por lo que les asignaremos el valor 2:
```{r}
data <- data %>% 
  mutate(
    thall = factor(if_else(is.na(as.numeric(thall)),2,as.numeric(thall)), 
                   levels = c(1,2,3),
                   labels = c("fixed defect","normal","reversable defect"))
  )

```


## Identifica y gestiona los valores extremos.
Estudiaremos los boxplots de las variables numéricas para observar si existen valores atípicos:

```{r, echo = FALSE}

# Boxplots
data_num %>% 
pivot_longer(colnames(data_num)) %>% 
  as.data.frame() %>% 
  ggplot(aes(y = value)) +    # Draw each column as histogram
  geom_boxplot(fill = "#404080", coef = 1.58) + 
  theme_minimal() +
  facet_wrap(~ name, scales = "free")
```
Vemos que todas las variables menos *age* muestran valores que están alejados de las medias y la mayoría de observaciones. Esta gráfica identifica como atípico el valor que $x < Q_1 - IQR\cdot 1.58$ o $x < Q_3 - IQR\cdot 1.58$ donde $IQR = Q_3 - Q_1$. La manera en la que vamos a tratarlos es asignarles el valor más cercano para que no sean considerados *outliers*.

```{r}

for (col in colnames(data_num)){
  value = data[[col]][data[[col]] %in% boxplot.stats(data[[col]])$out]
  res <- quantile(data[[col]], probs = c(0,0.25,0.5,0.75,1))
  q1 <- res[[2]]
  q3 <- res[[4]]
  iqr <- q3 - q1
  min_thshld <- q1 - 1.58*iqr
  max_thshld <- q3 + 1.58*iqr
  data[[col]][data[[col]] < min_thshld] = min_thshld
  data[[col]][data[[col]] > max_thshld] = max_thshld
}


data %>% 
  select_if(is.numeric) %>% 
pivot_longer(colnames(data_num)) %>% 
  as.data.frame() %>% 
  ggplot(aes(y = value)) +    # Draw each column as histogram
  geom_boxplot(fill = "#404080", coef = 1.58) + 
  theme_minimal() +
  facet_wrap(~ name, scales = "free")

```

```{r}

# outliers
boxplot.stats(data_num$oldpeak)$out

```
# Análisis de los datos

## Selección de los grupos de datos que se quieren analizar/comparar (p.
ej., si se van a comparar grupos de datos, ¿cuáles son estos grupos y
qué tipo de análisis se van a aplicar?)


```{r, fig.height = 10}


```
## Comprobación de la normalidad y homogeneidad de la varianza.

## Aplicación de pruebas estadísticas para comparar los grupos de datos.
En función de los datos y el objetivo del estudio, aplicar pruebas de
contraste de hipótesis, correlaciones, regresiones, etc. Aplicar al menos
tres métodos de análisis diferentes.

# Representación de los resultados a partir de tablas y gráficas.

Este apartado se puede responder a lo largo de la práctica, sin necesidad de concentrar todas las representaciones en este punto de la práctica.

# Resolución del problema. 

A partir de los resultados obtenidos, ¿cuáles son
las conclusiones? ¿Los resultados permiten responder al problema?

# Código. 

Hay que adjuntar el código, preferiblemente en R, con el que se ha
realizado la limpieza, análisis y representación de los datos. Si lo preferís,
también podéis trabajar en Python.

# Vídeo.


